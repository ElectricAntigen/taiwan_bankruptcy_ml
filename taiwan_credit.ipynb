{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\maxym\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\maxym\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maxym\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\maxym\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maxym\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.1.24)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\maxym\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\maxym\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\maxym\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ucimlrepo) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ucimlrepo) (2024.8.30)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\maxym\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maxym\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (2.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\maxym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install tensorflow\n",
    "%pip install ucimlrepo \n",
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bankrupt?</th>\n",
       "      <th>ROA(C) before interest and depreciation before interest</th>\n",
       "      <th>ROA(A) before interest and % after tax</th>\n",
       "      <th>ROA(B) before interest and depreciation after tax</th>\n",
       "      <th>Operating Gross Margin</th>\n",
       "      <th>Realized Sales Gross Margin</th>\n",
       "      <th>Operating Profit Rate</th>\n",
       "      <th>Pre-tax net Interest Rate</th>\n",
       "      <th>After-tax net Interest Rate</th>\n",
       "      <th>Non-industry income and expenditure/revenue</th>\n",
       "      <th>...</th>\n",
       "      <th>Net Income to Total Assets</th>\n",
       "      <th>Total assets to GNP price</th>\n",
       "      <th>No-credit Interval</th>\n",
       "      <th>Gross Profit to Sales</th>\n",
       "      <th>Net Income to Stockholder's Equity</th>\n",
       "      <th>Liability to Equity</th>\n",
       "      <th>Degree of Financial Leverage (DFL)</th>\n",
       "      <th>Interest Coverage Ratio (Interest expense to EBIT)</th>\n",
       "      <th>Net Income Flag</th>\n",
       "      <th>Equity to Liability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.370594</td>\n",
       "      <td>0.424389</td>\n",
       "      <td>0.405750</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.998969</td>\n",
       "      <td>0.796887</td>\n",
       "      <td>0.808809</td>\n",
       "      <td>0.302646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716845</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.622879</td>\n",
       "      <td>0.601453</td>\n",
       "      <td>0.827890</td>\n",
       "      <td>0.290202</td>\n",
       "      <td>0.026601</td>\n",
       "      <td>0.564050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.464291</td>\n",
       "      <td>0.538214</td>\n",
       "      <td>0.516730</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>0.797380</td>\n",
       "      <td>0.809301</td>\n",
       "      <td>0.303556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795297</td>\n",
       "      <td>0.008323</td>\n",
       "      <td>0.623652</td>\n",
       "      <td>0.610237</td>\n",
       "      <td>0.839969</td>\n",
       "      <td>0.283846</td>\n",
       "      <td>0.264577</td>\n",
       "      <td>0.570175</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.426071</td>\n",
       "      <td>0.499019</td>\n",
       "      <td>0.472295</td>\n",
       "      <td>0.601450</td>\n",
       "      <td>0.601364</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.796403</td>\n",
       "      <td>0.808388</td>\n",
       "      <td>0.302035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774670</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>0.623841</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>0.836774</td>\n",
       "      <td>0.290189</td>\n",
       "      <td>0.026555</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.399844</td>\n",
       "      <td>0.451265</td>\n",
       "      <td>0.457733</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.796967</td>\n",
       "      <td>0.808966</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739555</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.622929</td>\n",
       "      <td>0.583538</td>\n",
       "      <td>0.834697</td>\n",
       "      <td>0.281721</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.564663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.465022</td>\n",
       "      <td>0.538432</td>\n",
       "      <td>0.522298</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.797366</td>\n",
       "      <td>0.809304</td>\n",
       "      <td>0.303475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795016</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.623521</td>\n",
       "      <td>0.598782</td>\n",
       "      <td>0.839973</td>\n",
       "      <td>0.278514</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.575617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6814</th>\n",
       "      <td>0</td>\n",
       "      <td>0.493687</td>\n",
       "      <td>0.539468</td>\n",
       "      <td>0.543230</td>\n",
       "      <td>0.604455</td>\n",
       "      <td>0.604462</td>\n",
       "      <td>0.998992</td>\n",
       "      <td>0.797409</td>\n",
       "      <td>0.809331</td>\n",
       "      <td>0.303510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799927</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.623620</td>\n",
       "      <td>0.604455</td>\n",
       "      <td>0.840359</td>\n",
       "      <td>0.279606</td>\n",
       "      <td>0.027064</td>\n",
       "      <td>0.566193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815</th>\n",
       "      <td>0</td>\n",
       "      <td>0.475162</td>\n",
       "      <td>0.538269</td>\n",
       "      <td>0.524172</td>\n",
       "      <td>0.598308</td>\n",
       "      <td>0.598308</td>\n",
       "      <td>0.998992</td>\n",
       "      <td>0.797414</td>\n",
       "      <td>0.809327</td>\n",
       "      <td>0.303520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799748</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.623931</td>\n",
       "      <td>0.598306</td>\n",
       "      <td>0.840306</td>\n",
       "      <td>0.278132</td>\n",
       "      <td>0.027009</td>\n",
       "      <td>0.566018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6816</th>\n",
       "      <td>0</td>\n",
       "      <td>0.472725</td>\n",
       "      <td>0.533744</td>\n",
       "      <td>0.520638</td>\n",
       "      <td>0.610444</td>\n",
       "      <td>0.610213</td>\n",
       "      <td>0.998984</td>\n",
       "      <td>0.797401</td>\n",
       "      <td>0.809317</td>\n",
       "      <td>0.303512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797778</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.624156</td>\n",
       "      <td>0.610441</td>\n",
       "      <td>0.840138</td>\n",
       "      <td>0.275789</td>\n",
       "      <td>0.026791</td>\n",
       "      <td>0.565158</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6817</th>\n",
       "      <td>0</td>\n",
       "      <td>0.506264</td>\n",
       "      <td>0.559911</td>\n",
       "      <td>0.554045</td>\n",
       "      <td>0.607850</td>\n",
       "      <td>0.607850</td>\n",
       "      <td>0.999074</td>\n",
       "      <td>0.797500</td>\n",
       "      <td>0.809399</td>\n",
       "      <td>0.303498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811808</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.623957</td>\n",
       "      <td>0.607846</td>\n",
       "      <td>0.841084</td>\n",
       "      <td>0.277547</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>0.565302</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6818</th>\n",
       "      <td>0</td>\n",
       "      <td>0.493053</td>\n",
       "      <td>0.570105</td>\n",
       "      <td>0.549548</td>\n",
       "      <td>0.627409</td>\n",
       "      <td>0.627409</td>\n",
       "      <td>0.998080</td>\n",
       "      <td>0.801987</td>\n",
       "      <td>0.813800</td>\n",
       "      <td>0.313415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815956</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.626680</td>\n",
       "      <td>0.627408</td>\n",
       "      <td>0.841019</td>\n",
       "      <td>0.275114</td>\n",
       "      <td>0.026793</td>\n",
       "      <td>0.565167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.233902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6819 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bankrupt?   ROA(C) before interest and depreciation before interest  \\\n",
       "0             1                                           0.370594          \n",
       "1             1                                           0.464291          \n",
       "2             1                                           0.426071          \n",
       "3             1                                           0.399844          \n",
       "4             1                                           0.465022          \n",
       "...         ...                                                ...          \n",
       "6814          0                                           0.493687          \n",
       "6815          0                                           0.475162          \n",
       "6816          0                                           0.472725          \n",
       "6817          0                                           0.506264          \n",
       "6818          0                                           0.493053          \n",
       "\n",
       "       ROA(A) before interest and % after tax  \\\n",
       "0                                    0.424389   \n",
       "1                                    0.538214   \n",
       "2                                    0.499019   \n",
       "3                                    0.451265   \n",
       "4                                    0.538432   \n",
       "...                                       ...   \n",
       "6814                                 0.539468   \n",
       "6815                                 0.538269   \n",
       "6816                                 0.533744   \n",
       "6817                                 0.559911   \n",
       "6818                                 0.570105   \n",
       "\n",
       "       ROA(B) before interest and depreciation after tax  \\\n",
       "0                                              0.405750    \n",
       "1                                              0.516730    \n",
       "2                                              0.472295    \n",
       "3                                              0.457733    \n",
       "4                                              0.522298    \n",
       "...                                                 ...    \n",
       "6814                                           0.543230    \n",
       "6815                                           0.524172    \n",
       "6816                                           0.520638    \n",
       "6817                                           0.554045    \n",
       "6818                                           0.549548    \n",
       "\n",
       "       Operating Gross Margin   Realized Sales Gross Margin  \\\n",
       "0                    0.601457                      0.601457   \n",
       "1                    0.610235                      0.610235   \n",
       "2                    0.601450                      0.601364   \n",
       "3                    0.583541                      0.583541   \n",
       "4                    0.598783                      0.598783   \n",
       "...                       ...                           ...   \n",
       "6814                 0.604455                      0.604462   \n",
       "6815                 0.598308                      0.598308   \n",
       "6816                 0.610444                      0.610213   \n",
       "6817                 0.607850                      0.607850   \n",
       "6818                 0.627409                      0.627409   \n",
       "\n",
       "       Operating Profit Rate   Pre-tax net Interest Rate  \\\n",
       "0                   0.998969                    0.796887   \n",
       "1                   0.998946                    0.797380   \n",
       "2                   0.998857                    0.796403   \n",
       "3                   0.998700                    0.796967   \n",
       "4                   0.998973                    0.797366   \n",
       "...                      ...                         ...   \n",
       "6814                0.998992                    0.797409   \n",
       "6815                0.998992                    0.797414   \n",
       "6816                0.998984                    0.797401   \n",
       "6817                0.999074                    0.797500   \n",
       "6818                0.998080                    0.801987   \n",
       "\n",
       "       After-tax net Interest Rate  \\\n",
       "0                         0.808809   \n",
       "1                         0.809301   \n",
       "2                         0.808388   \n",
       "3                         0.808966   \n",
       "4                         0.809304   \n",
       "...                            ...   \n",
       "6814                      0.809331   \n",
       "6815                      0.809327   \n",
       "6816                      0.809317   \n",
       "6817                      0.809399   \n",
       "6818                      0.813800   \n",
       "\n",
       "       Non-industry income and expenditure/revenue  ...  \\\n",
       "0                                         0.302646  ...   \n",
       "1                                         0.303556  ...   \n",
       "2                                         0.302035  ...   \n",
       "3                                         0.303350  ...   \n",
       "4                                         0.303475  ...   \n",
       "...                                            ...  ...   \n",
       "6814                                      0.303510  ...   \n",
       "6815                                      0.303520  ...   \n",
       "6816                                      0.303512  ...   \n",
       "6817                                      0.303498  ...   \n",
       "6818                                      0.313415  ...   \n",
       "\n",
       "       Net Income to Total Assets   Total assets to GNP price  \\\n",
       "0                        0.716845                    0.009219   \n",
       "1                        0.795297                    0.008323   \n",
       "2                        0.774670                    0.040003   \n",
       "3                        0.739555                    0.003252   \n",
       "4                        0.795016                    0.003878   \n",
       "...                           ...                         ...   \n",
       "6814                     0.799927                    0.000466   \n",
       "6815                     0.799748                    0.001959   \n",
       "6816                     0.797778                    0.002840   \n",
       "6817                     0.811808                    0.002837   \n",
       "6818                     0.815956                    0.000707   \n",
       "\n",
       "       No-credit Interval   Gross Profit to Sales  \\\n",
       "0                0.622879                0.601453   \n",
       "1                0.623652                0.610237   \n",
       "2                0.623841                0.601449   \n",
       "3                0.622929                0.583538   \n",
       "4                0.623521                0.598782   \n",
       "...                   ...                     ...   \n",
       "6814             0.623620                0.604455   \n",
       "6815             0.623931                0.598306   \n",
       "6816             0.624156                0.610441   \n",
       "6817             0.623957                0.607846   \n",
       "6818             0.626680                0.627408   \n",
       "\n",
       "       Net Income to Stockholder's Equity   Liability to Equity  \\\n",
       "0                                0.827890              0.290202   \n",
       "1                                0.839969              0.283846   \n",
       "2                                0.836774              0.290189   \n",
       "3                                0.834697              0.281721   \n",
       "4                                0.839973              0.278514   \n",
       "...                                   ...                   ...   \n",
       "6814                             0.840359              0.279606   \n",
       "6815                             0.840306              0.278132   \n",
       "6816                             0.840138              0.275789   \n",
       "6817                             0.841084              0.277547   \n",
       "6818                             0.841019              0.275114   \n",
       "\n",
       "       Degree of Financial Leverage (DFL)  \\\n",
       "0                                0.026601   \n",
       "1                                0.264577   \n",
       "2                                0.026555   \n",
       "3                                0.026697   \n",
       "4                                0.024752   \n",
       "...                                   ...   \n",
       "6814                             0.027064   \n",
       "6815                             0.027009   \n",
       "6816                             0.026791   \n",
       "6817                             0.026822   \n",
       "6818                             0.026793   \n",
       "\n",
       "       Interest Coverage Ratio (Interest expense to EBIT)   Net Income Flag  \\\n",
       "0                                              0.564050                   1   \n",
       "1                                              0.570175                   1   \n",
       "2                                              0.563706                   1   \n",
       "3                                              0.564663                   1   \n",
       "4                                              0.575617                   1   \n",
       "...                                                 ...                 ...   \n",
       "6814                                           0.566193                   1   \n",
       "6815                                           0.566018                   1   \n",
       "6816                                           0.565158                   1   \n",
       "6817                                           0.565302                   1   \n",
       "6818                                           0.565167                   1   \n",
       "\n",
       "       Equity to Liability  \n",
       "0                 0.016469  \n",
       "1                 0.020794  \n",
       "2                 0.016474  \n",
       "3                 0.023982  \n",
       "4                 0.035490  \n",
       "...                    ...  \n",
       "6814              0.029890  \n",
       "6815              0.038284  \n",
       "6816              0.097649  \n",
       "6817              0.044009  \n",
       "6818              0.233902  \n",
       "\n",
       "[6819 rows x 96 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Taiwanese Bankruptcy Prediction [Dataset]. (2020). UCI Machine Learning Repository. https://doi.org/10.24432/C5004D.\n",
    "taiwanese_bankruptcy_prediction = fetch_ucirepo(id=572) \n",
    "\n",
    "df = pd.DataFrame(taiwanese_bankruptcy_prediction.data.original)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROA(C) before interest and depreciation before interest</th>\n",
       "      <th>ROA(A) before interest and % after tax</th>\n",
       "      <th>ROA(B) before interest and depreciation after tax</th>\n",
       "      <th>Operating Gross Margin</th>\n",
       "      <th>Realized Sales Gross Margin</th>\n",
       "      <th>Operating Profit Rate</th>\n",
       "      <th>Pre-tax net Interest Rate</th>\n",
       "      <th>After-tax net Interest Rate</th>\n",
       "      <th>Non-industry income and expenditure/revenue</th>\n",
       "      <th>Continuous interest rate (after tax)</th>\n",
       "      <th>...</th>\n",
       "      <th>Net Income to Total Assets</th>\n",
       "      <th>Total assets to GNP price</th>\n",
       "      <th>No-credit Interval</th>\n",
       "      <th>Gross Profit to Sales</th>\n",
       "      <th>Net Income to Stockholder's Equity</th>\n",
       "      <th>Liability to Equity</th>\n",
       "      <th>Degree of Financial Leverage (DFL)</th>\n",
       "      <th>Interest Coverage Ratio (Interest expense to EBIT)</th>\n",
       "      <th>Net Income Flag</th>\n",
       "      <th>Equity to Liability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.370594</td>\n",
       "      <td>0.424389</td>\n",
       "      <td>0.405750</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.998969</td>\n",
       "      <td>0.796887</td>\n",
       "      <td>0.808809</td>\n",
       "      <td>0.302646</td>\n",
       "      <td>0.780985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716845</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.622879</td>\n",
       "      <td>0.601453</td>\n",
       "      <td>0.827890</td>\n",
       "      <td>0.290202</td>\n",
       "      <td>0.026601</td>\n",
       "      <td>0.564050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.464291</td>\n",
       "      <td>0.538214</td>\n",
       "      <td>0.516730</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>0.797380</td>\n",
       "      <td>0.809301</td>\n",
       "      <td>0.303556</td>\n",
       "      <td>0.781506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795297</td>\n",
       "      <td>0.008323</td>\n",
       "      <td>0.623652</td>\n",
       "      <td>0.610237</td>\n",
       "      <td>0.839969</td>\n",
       "      <td>0.283846</td>\n",
       "      <td>0.264577</td>\n",
       "      <td>0.570175</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.426071</td>\n",
       "      <td>0.499019</td>\n",
       "      <td>0.472295</td>\n",
       "      <td>0.601450</td>\n",
       "      <td>0.601364</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.796403</td>\n",
       "      <td>0.808388</td>\n",
       "      <td>0.302035</td>\n",
       "      <td>0.780284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774670</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>0.623841</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>0.836774</td>\n",
       "      <td>0.290189</td>\n",
       "      <td>0.026555</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.399844</td>\n",
       "      <td>0.451265</td>\n",
       "      <td>0.457733</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.796967</td>\n",
       "      <td>0.808966</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>0.781241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739555</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.622929</td>\n",
       "      <td>0.583538</td>\n",
       "      <td>0.834697</td>\n",
       "      <td>0.281721</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.564663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.465022</td>\n",
       "      <td>0.538432</td>\n",
       "      <td>0.522298</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.797366</td>\n",
       "      <td>0.809304</td>\n",
       "      <td>0.303475</td>\n",
       "      <td>0.781550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795016</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.623521</td>\n",
       "      <td>0.598782</td>\n",
       "      <td>0.839973</td>\n",
       "      <td>0.278514</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.575617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6814</th>\n",
       "      <td>0.493687</td>\n",
       "      <td>0.539468</td>\n",
       "      <td>0.543230</td>\n",
       "      <td>0.604455</td>\n",
       "      <td>0.604462</td>\n",
       "      <td>0.998992</td>\n",
       "      <td>0.797409</td>\n",
       "      <td>0.809331</td>\n",
       "      <td>0.303510</td>\n",
       "      <td>0.781588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799927</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.623620</td>\n",
       "      <td>0.604455</td>\n",
       "      <td>0.840359</td>\n",
       "      <td>0.279606</td>\n",
       "      <td>0.027064</td>\n",
       "      <td>0.566193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815</th>\n",
       "      <td>0.475162</td>\n",
       "      <td>0.538269</td>\n",
       "      <td>0.524172</td>\n",
       "      <td>0.598308</td>\n",
       "      <td>0.598308</td>\n",
       "      <td>0.998992</td>\n",
       "      <td>0.797414</td>\n",
       "      <td>0.809327</td>\n",
       "      <td>0.303520</td>\n",
       "      <td>0.781586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799748</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.623931</td>\n",
       "      <td>0.598306</td>\n",
       "      <td>0.840306</td>\n",
       "      <td>0.278132</td>\n",
       "      <td>0.027009</td>\n",
       "      <td>0.566018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6816</th>\n",
       "      <td>0.472725</td>\n",
       "      <td>0.533744</td>\n",
       "      <td>0.520638</td>\n",
       "      <td>0.610444</td>\n",
       "      <td>0.610213</td>\n",
       "      <td>0.998984</td>\n",
       "      <td>0.797401</td>\n",
       "      <td>0.809317</td>\n",
       "      <td>0.303512</td>\n",
       "      <td>0.781546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797778</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.624156</td>\n",
       "      <td>0.610441</td>\n",
       "      <td>0.840138</td>\n",
       "      <td>0.275789</td>\n",
       "      <td>0.026791</td>\n",
       "      <td>0.565158</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6817</th>\n",
       "      <td>0.506264</td>\n",
       "      <td>0.559911</td>\n",
       "      <td>0.554045</td>\n",
       "      <td>0.607850</td>\n",
       "      <td>0.607850</td>\n",
       "      <td>0.999074</td>\n",
       "      <td>0.797500</td>\n",
       "      <td>0.809399</td>\n",
       "      <td>0.303498</td>\n",
       "      <td>0.781663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811808</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.623957</td>\n",
       "      <td>0.607846</td>\n",
       "      <td>0.841084</td>\n",
       "      <td>0.277547</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>0.565302</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6818</th>\n",
       "      <td>0.493053</td>\n",
       "      <td>0.570105</td>\n",
       "      <td>0.549548</td>\n",
       "      <td>0.627409</td>\n",
       "      <td>0.627409</td>\n",
       "      <td>0.998080</td>\n",
       "      <td>0.801987</td>\n",
       "      <td>0.813800</td>\n",
       "      <td>0.313415</td>\n",
       "      <td>0.786079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815956</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.626680</td>\n",
       "      <td>0.627408</td>\n",
       "      <td>0.841019</td>\n",
       "      <td>0.275114</td>\n",
       "      <td>0.026793</td>\n",
       "      <td>0.565167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.233902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6819 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ROA(C) before interest and depreciation before interest  \\\n",
       "0                                              0.370594         \n",
       "1                                              0.464291         \n",
       "2                                              0.426071         \n",
       "3                                              0.399844         \n",
       "4                                              0.465022         \n",
       "...                                                 ...         \n",
       "6814                                           0.493687         \n",
       "6815                                           0.475162         \n",
       "6816                                           0.472725         \n",
       "6817                                           0.506264         \n",
       "6818                                           0.493053         \n",
       "\n",
       "      ROA(A) before interest and % after tax  \\\n",
       "0                                   0.424389   \n",
       "1                                   0.538214   \n",
       "2                                   0.499019   \n",
       "3                                   0.451265   \n",
       "4                                   0.538432   \n",
       "...                                      ...   \n",
       "6814                                0.539468   \n",
       "6815                                0.538269   \n",
       "6816                                0.533744   \n",
       "6817                                0.559911   \n",
       "6818                                0.570105   \n",
       "\n",
       "      ROA(B) before interest and depreciation after tax  \\\n",
       "0                                              0.405750   \n",
       "1                                              0.516730   \n",
       "2                                              0.472295   \n",
       "3                                              0.457733   \n",
       "4                                              0.522298   \n",
       "...                                                 ...   \n",
       "6814                                           0.543230   \n",
       "6815                                           0.524172   \n",
       "6816                                           0.520638   \n",
       "6817                                           0.554045   \n",
       "6818                                           0.549548   \n",
       "\n",
       "      Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "0                   0.601457                     0.601457   \n",
       "1                   0.610235                     0.610235   \n",
       "2                   0.601450                     0.601364   \n",
       "3                   0.583541                     0.583541   \n",
       "4                   0.598783                     0.598783   \n",
       "...                      ...                          ...   \n",
       "6814                0.604455                     0.604462   \n",
       "6815                0.598308                     0.598308   \n",
       "6816                0.610444                     0.610213   \n",
       "6817                0.607850                     0.607850   \n",
       "6818                0.627409                     0.627409   \n",
       "\n",
       "      Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "0                  0.998969                   0.796887   \n",
       "1                  0.998946                   0.797380   \n",
       "2                  0.998857                   0.796403   \n",
       "3                  0.998700                   0.796967   \n",
       "4                  0.998973                   0.797366   \n",
       "...                     ...                        ...   \n",
       "6814               0.998992                   0.797409   \n",
       "6815               0.998992                   0.797414   \n",
       "6816               0.998984                   0.797401   \n",
       "6817               0.999074                   0.797500   \n",
       "6818               0.998080                   0.801987   \n",
       "\n",
       "      After-tax net Interest Rate  \\\n",
       "0                        0.808809   \n",
       "1                        0.809301   \n",
       "2                        0.808388   \n",
       "3                        0.808966   \n",
       "4                        0.809304   \n",
       "...                           ...   \n",
       "6814                     0.809331   \n",
       "6815                     0.809327   \n",
       "6816                     0.809317   \n",
       "6817                     0.809399   \n",
       "6818                     0.813800   \n",
       "\n",
       "      Non-industry income and expenditure/revenue  \\\n",
       "0                                        0.302646   \n",
       "1                                        0.303556   \n",
       "2                                        0.302035   \n",
       "3                                        0.303350   \n",
       "4                                        0.303475   \n",
       "...                                           ...   \n",
       "6814                                     0.303510   \n",
       "6815                                     0.303520   \n",
       "6816                                     0.303512   \n",
       "6817                                     0.303498   \n",
       "6818                                     0.313415   \n",
       "\n",
       "      Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "0                                 0.780985  ...                    0.716845   \n",
       "1                                 0.781506  ...                    0.795297   \n",
       "2                                 0.780284  ...                    0.774670   \n",
       "3                                 0.781241  ...                    0.739555   \n",
       "4                                 0.781550  ...                    0.795016   \n",
       "...                                    ...  ...                         ...   \n",
       "6814                              0.781588  ...                    0.799927   \n",
       "6815                              0.781586  ...                    0.799748   \n",
       "6816                              0.781546  ...                    0.797778   \n",
       "6817                              0.781663  ...                    0.811808   \n",
       "6818                              0.786079  ...                    0.815956   \n",
       "\n",
       "      Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "0                      0.009219            0.622879               0.601453   \n",
       "1                      0.008323            0.623652               0.610237   \n",
       "2                      0.040003            0.623841               0.601449   \n",
       "3                      0.003252            0.622929               0.583538   \n",
       "4                      0.003878            0.623521               0.598782   \n",
       "...                         ...                 ...                    ...   \n",
       "6814                   0.000466            0.623620               0.604455   \n",
       "6815                   0.001959            0.623931               0.598306   \n",
       "6816                   0.002840            0.624156               0.610441   \n",
       "6817                   0.002837            0.623957               0.607846   \n",
       "6818                   0.000707            0.626680               0.627408   \n",
       "\n",
       "      Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "0                               0.827890             0.290202   \n",
       "1                               0.839969             0.283846   \n",
       "2                               0.836774             0.290189   \n",
       "3                               0.834697             0.281721   \n",
       "4                               0.839973             0.278514   \n",
       "...                                  ...                  ...   \n",
       "6814                            0.840359             0.279606   \n",
       "6815                            0.840306             0.278132   \n",
       "6816                            0.840138             0.275789   \n",
       "6817                            0.841084             0.277547   \n",
       "6818                            0.841019             0.275114   \n",
       "\n",
       "      Degree of Financial Leverage (DFL)  \\\n",
       "0                               0.026601   \n",
       "1                               0.264577   \n",
       "2                               0.026555   \n",
       "3                               0.026697   \n",
       "4                               0.024752   \n",
       "...                                  ...   \n",
       "6814                            0.027064   \n",
       "6815                            0.027009   \n",
       "6816                            0.026791   \n",
       "6817                            0.026822   \n",
       "6818                            0.026793   \n",
       "\n",
       "      Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "0                                              0.564050                 1   \n",
       "1                                              0.570175                 1   \n",
       "2                                              0.563706                 1   \n",
       "3                                              0.564663                 1   \n",
       "4                                              0.575617                 1   \n",
       "...                                                 ...               ...   \n",
       "6814                                           0.566193                 1   \n",
       "6815                                           0.566018                 1   \n",
       "6816                                           0.565158                 1   \n",
       "6817                                           0.565302                 1   \n",
       "6818                                           0.565167                 1   \n",
       "\n",
       "      Equity to Liability  \n",
       "0                0.016469  \n",
       "1                0.020794  \n",
       "2                0.016474  \n",
       "3                0.023982  \n",
       "4                0.035490  \n",
       "...                   ...  \n",
       "6814             0.029890  \n",
       "6815             0.038284  \n",
       "6816             0.097649  \n",
       "6817             0.044009  \n",
       "6818             0.233902  \n",
       "\n",
       "[6819 rows x 95 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "6814    0\n",
       "6815    0\n",
       "6816    0\n",
       "6817    0\n",
       "6818    0\n",
       "Name: Bankrupt?, Length: 6819, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df.drop(columns=['Bankrupt?'])\n",
    "y = df['Bankrupt?']\n",
    "\n",
    "display(X)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into testing and training data (split 20-80)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the features (important if features have different scales)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', random_state=42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_pred_rf = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9707\n",
      "Confusion Matrix:\n",
      " [[1315    5]\n",
      " [  35    9]] \n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      1320\n",
      "           1       0.64      0.20      0.31        44\n",
      "\n",
      "    accuracy                           0.97      1364\n",
      "   macro avg       0.81      0.60      0.65      1364\n",
      "weighted avg       0.96      0.97      0.96      1364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "print(f'Accuracy: {accuracy_rf:.4f}')\n",
    "print('Confusion Matrix:\\n', conf_matrix_rf, '\\n')\n",
    "print('Classification Report:\\n', report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Borrowing dependency</td>\n",
       "      <td>0.055201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Continuous interest rate (after tax)</td>\n",
       "      <td>0.045160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Net Income to Total Assets</td>\n",
       "      <td>0.040956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Retained Earnings to Total Assets</td>\n",
       "      <td>0.039148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Liability to Equity</td>\n",
       "      <td>0.038644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Revenue Per Share (Yuan ¥)</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Quick Assets/Current Liability</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Fixed Assets to Assets</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Liability-Assets Flag</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Net Income Flag</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Feature  Importance\n",
       "39                   Borrowing dependency    0.055201\n",
       "9    Continuous interest rate (after tax)    0.045160\n",
       "85             Net Income to Total Assets    0.040956\n",
       "67      Retained Earnings to Total Assets    0.039148\n",
       "90                    Liability to Equity    0.038644\n",
       "..                                    ...         ...\n",
       "20             Revenue Per Share (Yuan ¥)    0.000000\n",
       "57         Quick Assets/Current Liability    0.000000\n",
       "75                 Fixed Assets to Assets    0.000000\n",
       "84                  Liability-Assets Flag    0.000000\n",
       "93                        Net Income Flag    0.000000\n",
       "\n",
       "[95 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame for feature importances\n",
    "feature_importances = pd.DataFrame({\n",
    "\t'Feature': X.columns,\n",
    "\t'Importance': rf_classifier.feature_importances_\n",
    "})\n",
    "\n",
    "# Sort the features by importance\n",
    "ranked_features = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "display(ranked_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "fnn = keras.Sequential([\n",
    "    layers.Dense(128, activation=\"relu\", input_shape=(X_train.shape[1],)),  \n",
    "    layers.Dropout(0.3),  \n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")  # Output layer for binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnn.compile(optimizer=\"adam\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8670 - loss: 0.3195 - val_accuracy: 0.9661 - val_loss: 0.1217\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9707 - loss: 0.1072 - val_accuracy: 0.9679 - val_loss: 0.1186\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9690 - loss: 0.1002 - val_accuracy: 0.9679 - val_loss: 0.1029\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9696 - loss: 0.0834 - val_accuracy: 0.9670 - val_loss: 0.1036\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9692 - loss: 0.0813 - val_accuracy: 0.9698 - val_loss: 0.1018\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9684 - loss: 0.0752 - val_accuracy: 0.9661 - val_loss: 0.1063\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9696 - loss: 0.0820 - val_accuracy: 0.9688 - val_loss: 0.1039\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9751 - loss: 0.0637 - val_accuracy: 0.9688 - val_loss: 0.1122\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9724 - loss: 0.0720 - val_accuracy: 0.9679 - val_loss: 0.1073\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9758 - loss: 0.0596 - val_accuracy: 0.9679 - val_loss: 0.1076\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9709 - loss: 0.0706 - val_accuracy: 0.9670 - val_loss: 0.1086\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9713 - loss: 0.0682 - val_accuracy: 0.9652 - val_loss: 0.1132\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9799 - loss: 0.0517 - val_accuracy: 0.9670 - val_loss: 0.1226\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9742 - loss: 0.0610 - val_accuracy: 0.9652 - val_loss: 0.1374\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9782 - loss: 0.0510 - val_accuracy: 0.9661 - val_loss: 0.1428\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9727 - loss: 0.0571 - val_accuracy: 0.9661 - val_loss: 0.1441\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9766 - loss: 0.0570 - val_accuracy: 0.9652 - val_loss: 0.1625\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.0507 - val_accuracy: 0.9698 - val_loss: 0.1560\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9803 - loss: 0.0493 - val_accuracy: 0.9661 - val_loss: 0.1724\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.0372 - val_accuracy: 0.9643 - val_loss: 0.1823\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.0419 - val_accuracy: 0.9670 - val_loss: 0.1909\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9847 - loss: 0.0335 - val_accuracy: 0.9688 - val_loss: 0.2117\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.0380 - val_accuracy: 0.9652 - val_loss: 0.2155\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9872 - loss: 0.0342 - val_accuracy: 0.9679 - val_loss: 0.2161\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.0343 - val_accuracy: 0.9679 - val_loss: 0.2389\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.0361 - val_accuracy: 0.9661 - val_loss: 0.2926\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9805 - loss: 0.0452 - val_accuracy: 0.9698 - val_loss: 0.2743\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.0335 - val_accuracy: 0.9633 - val_loss: 0.2993\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0323 - val_accuracy: 0.9698 - val_loss: 0.2957\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9908 - loss: 0.0228 - val_accuracy: 0.9670 - val_loss: 0.3364\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0303 - val_accuracy: 0.9688 - val_loss: 0.3630\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0305 - val_accuracy: 0.9698 - val_loss: 0.3561\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0246 - val_accuracy: 0.9670 - val_loss: 0.3138\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.0328 - val_accuracy: 0.9698 - val_loss: 0.3513\n",
      "Epoch 35/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0293 - val_accuracy: 0.9643 - val_loss: 0.3477\n",
      "Epoch 36/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0222 - val_accuracy: 0.9670 - val_loss: 0.3618\n",
      "Epoch 37/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0187 - val_accuracy: 0.9670 - val_loss: 0.3939\n",
      "Epoch 38/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0318 - val_accuracy: 0.9643 - val_loss: 0.3480\n",
      "Epoch 39/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0228 - val_accuracy: 0.9670 - val_loss: 0.3875\n",
      "Epoch 40/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 0.0168 - val_accuracy: 0.9652 - val_loss: 0.4563\n",
      "Epoch 41/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0240 - val_accuracy: 0.9670 - val_loss: 0.4483\n",
      "Epoch 42/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0247 - val_accuracy: 0.9679 - val_loss: 0.4781\n",
      "Epoch 43/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0167 - val_accuracy: 0.9670 - val_loss: 0.5181\n",
      "Epoch 44/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0175 - val_accuracy: 0.9679 - val_loss: 0.4816\n",
      "Epoch 45/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0150 - val_accuracy: 0.9661 - val_loss: 0.5427\n",
      "Epoch 46/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0115 - val_accuracy: 0.9652 - val_loss: 0.5070\n",
      "Epoch 47/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0215 - val_accuracy: 0.9615 - val_loss: 0.5337\n",
      "Epoch 48/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0243 - val_accuracy: 0.9661 - val_loss: 0.5115\n",
      "Epoch 49/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9908 - loss: 0.0223 - val_accuracy: 0.9652 - val_loss: 0.5002\n",
      "Epoch 50/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0151 - val_accuracy: 0.9670 - val_loss: 0.5594\n"
     ]
    }
   ],
   "source": [
    "history = fnn.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = fnn.predict(X_test)\n",
    "y_pred_fnn = (y_pred_prob > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9655\n",
      "Confusion Matrix:\n",
      " [[1311    9]\n",
      " [  38    6]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1320\n",
      "           1       0.40      0.14      0.20        44\n",
      "\n",
      "    accuracy                           0.97      1364\n",
      "   macro avg       0.69      0.56      0.59      1364\n",
      "weighted avg       0.95      0.97      0.96      1364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_fnn = accuracy_score(y_test, y_pred_fnn)\n",
    "conf_matrix_fnn = confusion_matrix(y_test, y_pred_fnn)\n",
    "report_fnn = classification_report(y_test, y_pred_fnn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_fnn:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_fnn)\n",
    "print(\"Classification Report:\\n\", report_fnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42, scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]))\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.9282\n",
      "Confusion Matrix:\n",
      " [[1234   86]\n",
      " [  12   32]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      1320\n",
      "           1       0.27      0.73      0.40        44\n",
      "\n",
      "    accuracy                           0.93      1364\n",
      "   macro avg       0.63      0.83      0.68      1364\n",
      "weighted avg       0.97      0.93      0.94      1364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "conf_matrix_gb = confusion_matrix(y_test, y_pred_gb)\n",
    "report_gb = classification_report(y_test, y_pred_gb)\n",
    "\n",
    "print(f\"Gradient Boosting Accuracy: {accuracy_gb:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_gb)\n",
    "print(\"Classification Report:\\n\", report_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(solver=\"liblinear\", class_weight=\"balanced\", random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8805\n",
      "Confusion Matrix:\n",
      " [[1165  155]\n",
      " [   8   36]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      1320\n",
      "           1       0.19      0.82      0.31        44\n",
      "\n",
      "    accuracy                           0.88      1364\n",
      "   macro avg       0.59      0.85      0.62      1364\n",
      "weighted avg       0.97      0.88      0.91      1364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "conf_matrix_log = confusion_matrix(y_test, y_pred_log)\n",
    "report_log = classification_report(y_test, y_pred_log)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_log:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_log)\n",
    "print(\"Classification Report:\\n\", report_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracies of the models\n",
    "model_names = ['Random Forest', 'Logistic Regression', 'FNN', 'Gradient Boosting']\n",
    "accuracies = [accuracy_rf, accuracy_log, accuracy_fnn, accuracy_gb]\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_names, accuracies, color=['blue', 'green', 'red', 'purple'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Model Accuracies')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
